{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습종류와 알고리즘(Learning Style and Algorithms)\n",
    "\n",
    "---\n",
    "\n",
    "<center><img src='Image/DataSplit_Concept1.png' width='700'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기초 알고리즘(Baseline): 분류분석\n",
    "\n",
    "> **\"일상 속 문제 중 여러개의 선택지 중에 정답을 고르는 문제\"**\n",
    "> - **회귀문제:** 데이터 변수(Feature, Variable)들을 사용하여 연속적인(Continuous) 값을 예측\n",
    "> - **분류문제:** 데이터 변수(Feature, Variable)들을 사용하여 이산적인(Discrete) 분류값을 예측\n",
    "\n",
    "---\n",
    "\n",
    "<center><img src='Image/ML_Type_Application_Circle.jpg' width='600'></center>  \n",
    "\n",
    "---\n",
    "\n",
    "> **\"$t$개의 값을 가지는 $k$차원 독립변수 $X_i$와 이에 대응하는 \"범주형 종속변수 $Y$\"와의 관계를 정량적으로 찾는 알고리즘\"**   \n",
    "> - 객관식 시험문제의 정답을 찾는 문제가 분류분석\n",
    "> - 주관식 시험문제의 숫자형 정답을 찾는 문제가 회귀분석\n",
    "\n",
    "\n",
    "| Regression Algorithms | Instance-based Algorithms | Regularization Algorithms | Decision Tree Algorithms | Bayesian Algorithms | Artificial Neural Network Algorithms |\n",
    "|------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| <img src='Image/Regression-Algorithms.png' width='150'> | <img src='Image/Instance-based-Algorithms.png' width='150'> | <img src='Image/Regularization-Algorithms.png' width='150'> | <img src='Image/Decision-Tree-Algorithms.png' width='150'> | <img src='Image/Bayesian-Algorithms.png' width='150'> | <img src='Image/Artificial-Neural-Network-Algorithms.png' width='150'> |\n",
    "| Ordinary Least Squares Regression (OLSR) | k-Nearest Neighbor (kNN) | Ridge Regression | Classification and Regression Tree (CART) | Naive Bayes | Perceptron |\n",
    "| Linear Regression | Learning Vector Quantization (LVQ) | Least Absolute Shrinkage and Selection Operator (LASSO) | Iterative Dichotomiser 3 (ID3) | Gaussian Naive Bayes | Back-Propagation |\n",
    "| Logistic Regression | Self-Organizing Map (SOM) | Elastic Net | C4.5 and C5.0 (different versions of a powerful approach) | Multinomial Naive Bayes | Hopfield Network |\n",
    "| Stepwise Regression | Locally Weighted Learning (LWL) | Least-Angle Regression (LARS) | Chi-squared Automatic Interaction Detection (CHAID) | Averaged One-Dependence Estimators (AODE) | Radial Basis Function Network (RBFN) |\n",
    "| Multivariate Adaptive Regression Splines (MARS) | - | - | Decision Stump | Bayesian Belief Network (BBN) | - |\n",
    "| Locally Estimated Scatterplot Smoothing (LOESS) | - | - | M5 | Bayesian Network (BN) | - |\n",
    "| - | - | - | Conditional Decision Trees | - | - |\n",
    "\n",
    "- **Target Algorithm:**\n",
    "> - Logistic Regression\n",
    "> - Ordinal Regression\n",
    "> - Cox Regression\n",
    "> - Naïve Bayes\n",
    "> - Stochastic Gradient Descent\n",
    "> - K-Nearest Neighbours\n",
    "> - Decision Tree\n",
    "> - Random Forest\n",
    "> - Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n",
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
      "(569, 30) (569,)\n"
     ]
    }
   ],
   "source": [
    "# Classification\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "raw = load_breast_cancer()\n",
    "print(raw.DESCR)\n",
    "print(raw.keys())\n",
    "print(raw.data.shape, raw.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival of passengers on the Titanic\n",
      "   Class     Sex    Age Survived  Freq\n",
      "0    1st    Male  Child       No     0\n",
      "1    2nd    Male  Child       No     0\n",
      "2    3rd    Male  Child       No    35\n",
      "3   Crew    Male  Child       No     0\n",
      "4    1st  Female  Child       No     0\n",
      "5    2nd  Female  Child       No     0\n",
      "6    3rd  Female  Child       No    17\n",
      "7   Crew  Female  Child       No     0\n",
      "8    1st    Male  Adult       No   118\n",
      "9    2nd    Male  Adult       No   154\n",
      "10   3rd    Male  Adult       No   387\n",
      "11  Crew    Male  Adult       No   670\n",
      "12   1st  Female  Adult       No     4\n",
      "13   2nd  Female  Adult       No    13\n",
      "14   3rd  Female  Adult       No    89\n",
      "15  Crew  Female  Adult       No     3\n",
      "16   1st    Male  Child      Yes     5\n",
      "17   2nd    Male  Child      Yes    11\n",
      "18   3rd    Male  Child      Yes    13\n",
      "19  Crew    Male  Child      Yes     0\n",
      "20   1st  Female  Child      Yes     1\n",
      "21   2nd  Female  Child      Yes    13\n",
      "22   3rd  Female  Child      Yes    14\n",
      "23  Crew  Female  Child      Yes     0\n",
      "24   1st    Male  Adult      Yes    57\n",
      "25   2nd    Male  Adult      Yes    14\n",
      "26   3rd    Male  Adult      Yes    75\n",
      "27  Crew    Male  Adult      Yes   192\n",
      "28   1st  Female  Adult      Yes   140\n",
      "29   2nd  Female  Adult      Yes    80\n",
      "30   3rd  Female  Adult      Yes    76\n",
      "31  Crew  Female  Adult      Yes    20\n"
     ]
    }
   ],
   "source": [
    "# Classification\n",
    "import statsmodels.api as sm\n",
    "raw = sm.datasets.get_rdataset(\"Titanic\", package=\"datasets\")\n",
    "print(raw.title)\n",
    "print(raw.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>891.0</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>1.00</td>\n",
       "      <td>223.5000</td>\n",
       "      <td>446.0000</td>\n",
       "      <td>668.5</td>\n",
       "      <td>891.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>891.0</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>714.0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>0.42</td>\n",
       "      <td>20.1250</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>80.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>891.0</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.9104</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>31.0</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count        mean         std   min       25%       50%    75%  \\\n",
       "PassengerId  891.0  446.000000  257.353842  1.00  223.5000  446.0000  668.5   \n",
       "Survived     891.0    0.383838    0.486592  0.00    0.0000    0.0000    1.0   \n",
       "Pclass       891.0    2.308642    0.836071  1.00    2.0000    3.0000    3.0   \n",
       "Age          714.0   29.699118   14.526497  0.42   20.1250   28.0000   38.0   \n",
       "SibSp        891.0    0.523008    1.102743  0.00    0.0000    0.0000    1.0   \n",
       "Parch        891.0    0.381594    0.806057  0.00    0.0000    0.0000    0.0   \n",
       "Fare         891.0   32.204208   49.693429  0.00    7.9104   14.4542   31.0   \n",
       "\n",
       "                  max  \n",
       "PassengerId  891.0000  \n",
       "Survived       1.0000  \n",
       "Pclass         3.0000  \n",
       "Age           80.0000  \n",
       "SibSp          8.0000  \n",
       "Parch          6.0000  \n",
       "Fare         512.3292  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification\n",
    "import pandas as pd\n",
    "location = r'.\\Data\\Titanic\\Titanic.csv'\n",
    "raw = pd.read_csv(location)\n",
    "display(raw)\n",
    "raw.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리 방향(Preprocessing)\n",
    "\n",
    "- **목표:** \n",
    "> - 대량으로 수집된 데이터는 그대로 활용 어려움\n",
    "> - 잘못 수집/처리 된 데이터는 엉뚱한 결과를 발생\n",
    "> - 알고리즘이 학습이 가능한 형태로 데이터를 정리\n",
    "<center><img src='Image/DataAnalysis_Time.jpg' width='500'></center> \n",
    "---\n",
    "\n",
    "> **세부항목:**  \n",
    "> - 데이터 결합\n",
    "> - 결측값 처리\n",
    "> - 이상치 처리\n",
    "> - 자료형 변환\n",
    "> - 데이터 변환\n",
    "> - 데이터 분리\n",
    "> - 스케일 조정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함수세팅 및 추정 방향(Modeling): 로지스틱 회귀분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **\"연속형 종속변수 예시\"**\n",
    "<center><img src='Image/Example_LinearRegression.png' width='600'></center>\n",
    "\n",
    "> **\"범주형 종속변수 예시\"**\n",
    "> - Outlier가 존재하면 Linear Regression의 추정은 왜곡을 발생시킴\n",
    "<center><img src='Image/Example_LinearRegression_Limit.png' width='600'></center>\n",
    "\n",
    "- **회귀분석 vs 분류분석:**\n",
    "\n",
    "> **회귀분석:** 연속형 종속변수 Y의 값을 추론\n",
    "> - 혈압의 경우 값 자체로 의미가 있지만 암발생은 발생(1)과 미발생(0) 사이의 중간값 무의미\n",
    "> - 회귀분석으로 범주형 종속변수를 추론하면 범위가 맞지 않아 암발생 여부의 해석이 왜곡\n",
    ">> - 나이가 많아지면 무조건 암이 걸리거나 나이가 어리면 무조건 암이 걸리지 않는 왜곡 발생\n",
    "> - Y가 범주형일 경우 사용할 수 없는 문제 존재하며 이를 추정하기 위한 접근 필요\n",
    "\n",
    "> **분류분석:** 범주형(범주/카테고리/클래스/라벨) 종속변수 Y의 소속을 추론\n",
    "> - 0과 1사이의 값을 가지면서 S자 형태로 적합하는 함수가 시그모이드 함수(Sigmoid Function)\n",
    "> - 종속변수 카테고리의 갯수와 방향에 따라 Binary/Multi-class/Multi-label로 구분\n",
    ">> - **Binary Classification:** 각 sample 데이터가 2개의 카테고리 중 \"어떤 것\"인지 추론하는 문제 (ex. 성별 추론 / 스팸메일 추론)\n",
    ">> - **Multi-class classification:** 각 sample 데이터가 2개 이상의 카테고리 중 \"어떤 것\"인지 추론하는 문제 (ex. 사진으로 동물 이름 추론)\n",
    ">> - **Multi-label classification:** 각 sample 데이터가 2개 이상의 카테고리 중 \"어떠한 것들\"인지 추론하는 문제 (ex. 뉴스기사는 스포츠/사람/지역 관련임을 추론)\n",
    "<center><img src='Image/Example_LogisticRegression.png' width='600'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **로지스틱분석(Logistic Regression):** 분류문제를 푸는 대표적인 알고리즘\n",
    "\n",
    "> - 범주형 종속변수의 데이터를 추정하기 위한 \"변환과정\" 필요\n",
    "> - \"Logistic/Sigmoid Function\"를 사용하여 곡선(S-curve) 형태로 변환\n",
    ">\n",
    "> <center><img src='Image/Linear_Logistic.png' width='600'></center>\n",
    ">\n",
    "> **(1) 회귀분석 세팅:**\n",
    ">\n",
    ">\\begin{align*}\n",
    "Y \\approx \\hat{Y} &= f(X_1, X_2, ..., X_k) \\\\\n",
    "&= \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\cdots + \\beta_kX_k \\\\\n",
    "&= X\\beta\n",
    "\\end{align*}\n",
    ">\n",
    "> **(2) 종속변수 변환(Logistic/Sigmoid Fitting):** Binary Classification 반영하는 곡선 형태로 변경\n",
    ">\n",
    ">\\begin{align*}\n",
    "Pr(Y) &= \\dfrac{1}{1+exp(-X\\beta)} \\\\\n",
    "&= \\dfrac{exp(X\\beta)}{1+exp(X\\beta)}\n",
    "\\end{align*}\n",
    ">\n",
    "> **(3) 로짓 변환(Logit Transformation):** 독립변수의 선형관계 형태로 일반화(데이터의 변수들로 Y=1인 확률 추정)\n",
    ">\n",
    ">\\begin{align*}\n",
    "Pr(Y) \\left( 1 + exp(X\\beta) \\right) &= exp(X\\beta) \\\\\n",
    "Pr(Y) &= \\left( 1 - Pr(Y) \\right) exp(X\\beta) \\\\\n",
    "\\text{Odds(ratio):} \\left( \\dfrac{Pr(Y)}{1 - Pr(Y)} \\right) &= exp(X\\beta) \\\\\n",
    "\\text{Logit(log-odds): } log \\left( \\dfrac{Pr(Y)}{1 - Pr(Y)} \\right) &= X\\beta = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\cdots + \\beta_kX_k\n",
    "\\end{align*}\n",
    "\n",
    "- **비용함수(Cost Function):** 계수 추정을 위해 알고리즘의 예측값($\\hat{Y}$)과 실제값($Y$)의 차이를 평가하는 함수\n",
    "> - **이슈: Linear Regression 비용함수 적용 어려움**    \n",
    ">\n",
    ">> (1) 분류문제에서는 $\\hat{Y}$를 사용한 잔차(에러)계산이 무의미    \n",
    ">> (2) 회귀분석의 Cost Function($Y - \\hat{Y}$)에 종속변수 및 로짓 변환을 하면 Non-convex 형태가 되서 최소값(Global Minimum) 추정 어려움    \n",
    ">> (3) 정확한 계수추정 방정식을 계산할 수 없기에 확률론적 접근 필요    \n",
    "> <center><img src='Image/Cost_Comparison.png' width='600'></center>\n",
    ">\n",
    "> - **신규:** 회귀문제와 달리 새로운 비용함수가 필요하고 이를 최소로 하는 계수(coefficient)를 추정\n",
    ">> - Y를 잘 분류하면 cost=0으로 그렇지 않으면 cost=$\\infty$가 되어 Penalty를 주는 방향\n",
    ">>> - (빨간선 예시) 실제값이 1일때 예측값이 1이면 Cost는 0\n",
    ">>> - (빨간선 예시) 실제값이 1일때 예측값이 0이면 Cost는 무한대\n",
    ">\n",
    "> \\begin{align*}\n",
    "\\text{Cost} = \\begin{cases} -log(Pr(\\hat{Y})) ~~~~ & \\text{in the case of } ~~~ Y = 1 \\\\ -log(1-Pr(\\hat{Y})) ~~~~ & \\text{in the case of } ~~~ Y = 0 \\end{cases}\n",
    "\\end{align*}\n",
    "> <center><img src='Image/Cost_Logistic.png' width='600'></center>\n",
    ">\n",
    ">\n",
    "> - **Cross Entropy: Y가 0과 1인 경우의 Cost를 결합하여 하나의 식으로 표현**\n",
    ">> - 로지스틱 알고리즘은 비용함수로 Cross Entropy를 사용하고 평균을 최소로 하는 계수 추정\n",
    ">> - Y=0인 경우 빨간부분이 사라지고 Y=1인 경우 파란부분이 사라져 Class별로 독립적으로 작동\n",
    ">> - 분류문제의 Cost 함수는 다양하고 많지만 통계학적으로 계수 추정에 효율적인 편\n",
    ">> - Convex 형태이기 때문에 Global Minimum을 찾기가 용이함\n",
    ">> - 추정된 계수($\\hat{\\beta}$)로 방정식을 만들어 어떠한 데이터로도 Y=1인 확률을 계산할 수 있음\n",
    ">>\n",
    ">>\\begin{align*}\n",
    "\\text{cost} &= \\sum_{i=1}^{m} \\left[ - \\color{red}{\\hat{Y}_{i} log (Pr(\\hat{Y}_{i}))} - \\color{blue}{(1-\\hat{Y}_{i}) log (1-Pr(\\hat{Y}_{i}))} \\right] \\\\\n",
    "\\hat{\\beta} &= \\underset{\\beta}{\\arg\\min} \\sum_{i=1}^{m} \\left[\\text{cost} \\right] \\\\\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 확률론적 모형(Probabilistic Model): 통계적 모형\n",
    "> **\"종속변수의 발생가능성을 최대(최소)로하는 $\\beta$를 추정\"**\n",
    "> - 범주형 분류문제를 확률로 반영하였기 때문에 확률론적 방식으로 접근\n",
    ">> 1) 계수를 임의의 초기값을 사용하여 Logit 추정   \n",
    ">> 2) 추정된 Logit으로 Likelihood 계산   \n",
    ">> 3) Log-likelihood를 증가시키는 방향으로 $\\hat{\\beta}$를 업데이트하며 최적값 추정\n",
    "\n",
    "**1) Y의 발생가능성(Likelihood):** \n",
    "\n",
    "\\begin{align*}\n",
    "Pr(Y_{i} \\,\\big|\\, X_{i}) &= \\prod_{i=1}^m Pr(Y_{i})^{Y_{i}} [1-Pr(Y_{i})]^{1-Y_{i}}\n",
    "\\end{align*}\n",
    "\n",
    "**2) 더하기 사용을 위한 Log 변환(Log-Likelihood):** \n",
    "\n",
    "\\begin{align*}\n",
    "\\text{LL} &= \\log Pr(Y_{i} \\,\\big|\\, X_{i}) \\\\\n",
    "&= \\sum_{i=1}^{m} \\left[ Y_{i} log (Pr(Y_{i})) + (1-Y_{i}) log (1-Pr(Y_{i})) \\right]\n",
    "\\end{align*}\n",
    "\n",
    "**3) Log-Likelihood의 그레디언트(미분,기울기)는 \"최소\"가 되어야 함:** 최적화 과정\n",
    "\n",
    "\\begin{align*}\n",
    "- \\dfrac{d}{d\\beta} \\text{LL} &= \\text{minimum} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "**4) 수치해석 방법론으로 초기값 $\\beta$의 반복적 업데이트를 통한 $\\hat{\\beta}$ 추정:**\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{\\beta}^{new} &= \\hat{\\beta}^{old} - (\\dfrac{d^2}{d\\beta d\\beta^T} \\text{LL})^{-1} \\dfrac{d}{d\\beta} \\text{LL}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "**5) 결과 활용**\n",
    "\n",
    "> **(1) 결과 해석:** $\\hat{Logit}$과 $\\hat{Odds}$ 추정으로 가능\n",
    "> \\begin{align*}\n",
    "\\text{Logit: } log \\left( \\dfrac{Pr(Y)}{1 - Pr(Y)} \\right) &= X\\hat{\\beta} = \\hat{\\beta}_0 + \\hat{\\beta}_1X_1 + \\hat{\\beta}_2X_2 + \\cdots + \\hat{\\beta}_kX_k \\\\\n",
    "\\text{Odds: } \\left( \\dfrac{Pr(Y)}{1 - Pr(Y)} \\right) &= exp(X\\hat{\\beta}) \\\\\n",
    "\\end{align*}\n",
    ">\n",
    "> **(2) 회귀분석과 달리 종속변수의 로짓변환 값을 독립변수들의 선형관계로 추정하므로 해석에 주의**\n",
    ">\n",
    "> \\begin{align*}\n",
    "\\left( \\dfrac{Pr(Y)}{1 - Pr(Y)} \\right) = exp(0.01 + 0.8 X_1)\n",
    "\\end{align*}\n",
    "> - (회귀분석) $X_1$이 1만큼 증가하면 $Y$는 0.8만큼 증가\n",
    "> - (로지스틱) $X_1$이 1만큼 증가하면 암에 걸리지 않을 확률보다 암에 걸릴 확률이 $exp(0.8) = 2.23$배 더 높음\n",
    ">\n",
    "> **(3) Y 확률 예측:**\n",
    ">\n",
    "> \\begin{align*}\n",
    "Pr(\\hat{Y}) &= \\dfrac{1}{1+exp(-X\\hat{\\beta})} = \\dfrac{exp(X\\hat{\\beta})}{1+exp(X\\hat{\\beta})}\n",
    "\\end{align*}\n",
    ">\n",
    "> **(4) 분류 의사결정:** 기본 임계값은 0.5로 이상시 1, 그렇지 않으면 0으로 분류\n",
    ">\n",
    "> \\begin{align*}\n",
    "\\hat{Y} = \\begin{cases} 1 ~~~~ \\text{if } ~~~ Pr(\\hat{Y}) >= 0.5 \\\\ 0 ~~~~ \\text{if } ~~~ Pr(\\hat{Y}) < 0.5 \\end{cases}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-class 분류문제\n",
    "\n",
    "<!-- https://mangkyu.tistory.com/36?category=767742 -->\n",
    "\n",
    "- **Binary vs. Multi-class:**\n",
    "\n",
    "<center><img src='Image/Classification_BinaryMuticlass.png' width='600'></center>\n",
    "\n",
    "- **방향:** N개의 Class(Category)가 있는 문제는 N개의 Binary Classification으로 바꾸어 해결\n",
    "\n",
    "> - 1) 세모가 Positive일때 Y가 세모에 속할 확률\n",
    "> - 2) 네모가 Positive일때 Y가 네모에 속할 확률\n",
    "> - 3) 엑스가 Positive일때 Y가 엑스에 속할 확률\n",
    ">\n",
    "> **데이터가 주어지면 3개의 경우를 모두 적용하여 최대 확률을 갖는 Class로 추정**\n",
    "\n",
    "<center><img src='Image/Classification_Multiclass.png' width='600'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검증지표 방향(Evaluation Metrics)\n",
    "\n",
    "- **\"문제해결 지표와 알고리즘 지표는 같을 수 있으나 대부분은 다른 편\"**\n",
    "> **1) 문제해결 검증지표: 실제 문제를 잘 해결하는지 평가**   \n",
    "> **2) 알고리즘 검증지표: 데이터의 패턴이 잘 추출되고 예측의 정확성을 평가\"**   \n",
    ">> - 알고리즘 성능이 좋은것과 문제해결이 가능한 것은 다르기 때문에 문제해결 지표와 알고리즘 지표는 같을 수 있으나 대부분은 다른 편\n",
    ">> - 알고리즘 검증지표는 없어도 되지만 문제해결 검증지표는 반드시 필요    \n",
    ">> - (이론적)알고리즘들은 일반적으로 특정 \"알고리즘 검증지표\"를 향상시키는 방향으로 개발됨\n",
    "<center><img src='Image/Analysis_Process.png' width='800'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 대표적인 검증지표\n",
    "\n",
    "<center><img src='Image/DataSplit_Concept1.png' width='700'></center>\n",
    "\n",
    "---\n",
    "\n",
    "**1) 분류별 종류**\n",
    "\n",
    "<center><img src='Image/Evaluation_Metric_Types.png' width='600'></center>\n",
    "\n",
    "> - **Statistical Metrics:** Correlation\n",
    ">> - 입력(Input): -무한대 ~ 무한대 범위의 연속형 값\n",
    ">> - 출력(Output): 이론적으론 -1 ~ 1 범위의 연속형 값\n",
    "> - **Regression Metrics:** MSE, MSPE, RMSE, RMSLE, MAE, MAPE, MPE, R^2, Adjusted R^&2, ... (Y의 범위가 무한대가 가능한 연속형일때)\n",
    ">> - 입력(Input): -무한대 ~ 무한대 범위의 연속형 값\n",
    ">> - 출력(Output): 이론적으론 0 ~ 무한대 범위의 연속형 값\n",
    "> - **Classification Metrics:** Log Loss, Cross-entropy, ROC, AUC, Gini, Confusion Matrix, Accuracy, Precision, Recall, F1-score, Classification Report, KS Statistic, Concordant-Discordant Ratio ... (Y가 2개 또는 그 이상개수의 이산형일때)\n",
    ">> - 입력(Input): -무한대 ~ 무한대 범위의 연속형 값\n",
    ">> - 출력(Output): 알고리즘 종류에 따라 출력이 달라질 수 있음\n",
    ">>> - 확률(Probability): 0 ~ 1 범위의 연속형 값 (Logistic Regression, Random Forest, Gradient Boosting, Adaboost, ...)\n",
    ">>> - 집단(Class): 0 또는 1의 이산형 값 (SVM, KNN, ...)\n",
    "> - **Ranking Metrics:** Gain, Lift, MRR, DCG, NDCG, ...\n",
    "> - **Computer Vision Metrics:** PSNR, SSIM, IoU, ...\n",
    "> - **NLP Metrics:** Perplexity, BLEU score, ...\n",
    "> - **Deep Learning Related Metrics:** Inception score, Frechet Inception distance, ...\n",
    "> - **Real Problem:** ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분류분석 검증지표 및 해석하기\n",
    "\n",
    "---\n",
    "- **Structure:**\n",
    "\n",
    "<center><img src='Image/DataSplit_Concept1.png' width='700'></center>\n",
    "\n",
    "<center><img src='Image/Evaluation_Yhat.PNG' width='600'></center>\n",
    "\n",
    "- **실제 예측결과 분포(히스토그램):**\n",
    "\n",
    "<center><img src='Image/Evaluation_Prediction_Hist.png' width='500'></center>\n",
    "\n",
    "---\n",
    "\n",
    "**1) 오차행렬(Confusion Matrix):** 정답 클래스와 알고리즘이 예측한 클래스가 일치하는지 갯수로 정리  \n",
    "\n",
    "- Binary Classification\n",
    "\n",
    "| 　 | 예측 클래스 0 | 예측 클래스 1 |\n",
    "|:-:|:-:|:-:|\n",
    "| 정답 클래스 0 | 정답 클래스가 0, 예측 클래스가 0인 표본의 수 <br> (3) | 정답 클래스가 0, 예측 클래스가 1인 표본의 수 <br> (0)|\n",
    "| 정답 클래스 1 | 정답 클래스가 1, 예측 클래스가 0인 표본의 수 <br> (1) | 정답 클래스가 1, 예측 클래스가 1인 표본의 수 <br> (3) |\n",
    "\n",
    "- Multi-class Classification\n",
    "\n",
    "| 　 | 예측 클래스 0 | 예측 클래스 1 | … | 예측 클래스 K |\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "| 정답 클래스 0 | 정답 클래스가 0, 예측 클래스가 0인 표본의 수 | 정답 클래스가 0, 예측 클래스가 1인 표본의 수 | … | 정답 클래스가 0, 예측 클래스가 K인 표본의 수 |\n",
    "| 정답 클래스 1 | 정답 클래스가 1, 예측 클래스가 0인 표본의 수 | 정답 클래스가 1, 예측 클래스가 1인 표본의 수 | … | 정답 클래스가 1, 예측 클래스가 K인 표본의 수 |\n",
    "| … | … | … | … | … |\n",
    "| 정답 클래스 K | 정답 클래스가 K, 예측 클래스가 0인 표본의 수 | 정답 클래스가 K, 예측 클래스가 1인 표본의 수 | … | 정답 클래스가 K, 예측 클래스가 K인 표본의 수 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) 정확도(Accuracy):** 전체 샘플 중 정확하게 예측한 클래스의 비율(클래스 0과 1을 모두 포함)\n",
    "> - 예측이 정답과 얼마나 정확한가?\n",
    "\n",
    "| 　 | 예측 클래스 0 | 예측 클래스 1 |\n",
    "|:-:|:-:|:-:|\n",
    "| 정답 클래스 0 | True Negative (TN) <br> (3) | False Positive (FP) <br> (0) |\n",
    "| 정답 클래스 1 | False Negative (FN) <br> (1) | True Positive (TP) <br> (3) |\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{accuracy} = \\frac{TP + TN}{TP + FN + FP + TN}\n",
    "\\end{align*}\n",
    "\n",
    "**3) 정밀도(Precision):** 클래스 1로 예측한 값들 중 실제 클래스 1의 비율\n",
    "> - 예측한 것중 정답의 비율은?\n",
    "> - 잘못예측한 클래스 1의 비중을 파악하고 줄이는데 목적\n",
    "> - 암환자가 아닌데 암에 걸릴거라고 예측하여 과도한 사람들의 검진 증가 우려\n",
    "\n",
    "| 　 | 예측 클래스 1 |\n",
    "|:-:|:-:|\n",
    "| 정답 클래스 0 | False Positive (FP) <br> (0) |\n",
    "| 정답 클래스 1 | True Positive (TP) <br> (3) |\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{accuracy} = \\frac{TP}{TP + FP}\n",
    "\\end{align*}\n",
    "\n",
    "**4) 재현율(Recall/Sensitivity/True Positive Rate):** 실제 클래스 1 값들 중 예측 클래스 1의 비율\n",
    "> - 정답 클래스 1중 예측으로 맞춘 비율은?\n",
    "> - 잘못예측한 클래스 0의 비중을 파악하고 줄이는데 목적\n",
    "> - 암환자인데 암이 아니라 예측하여 과도한 사망율 증가 우려\n",
    "\n",
    "| 　 | 예측 클래스 0 | 예측 클래스 1 |\n",
    "|:-:|:-:|:-:|\n",
    "| 정답 클래스 1 | False Negative (FN) <br> (1) | True Positive (TP) <br> (3) |\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{accuracy} = \\frac{TP}{TP + FN}\n",
    "\\end{align*}\n",
    "\n",
    "**5) F1점수(F1-score):** 정밀도와 재현율의 Trade Off관계 반영위해 (가중)평균으로 모두 잘 맞추었는지 평가\n",
    "> - 정밀도과 재현율이 모두 중요한 문제의 경우 중요\n",
    "> - 정밀도와 재현율을 따로 보면 한쪽으로 편중된(Bias) 의사결정이 될 수 있는 위험\n",
    "> - 다양한 평균의 종류 중 조화평균을 사용하여 계산다양한 평균의 종류 중 조화평균을 사용하여 계산\n",
    "> - 정밀도과 재현율 중 한쪽에 치우치지 않았을 때 높은 값\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{accuracy} = \\frac{2 * precision * recall}{precision + recall}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6) ROC커브(Receiver Operator Characteristic Curve):** 분류 기준값(Threshold)에 따라 재현율과 거짓율의 검증지표의 변화를 확인하기 위한 시각화 지표\n",
    "\n",
    "<center><img src='Image/Evaluation_ROC_Distribution.png' width='500'></center>\n",
    "\n",
    "- **재현율(Recall/Sensitivity/True Positive Rate):** 실제 클래스 1 값들 중 예측 클래스 1의 비율\n",
    "> - 정답 클래스 1중 예측으로 맞춘 비율은?\n",
    "> - 잘못예측한 클래스 0의 비중을 파악하고 줄이는데 목적\n",
    "> - 암환자인데 암이 아니라 예측하여 과도한 사망율 증가 우려\n",
    "\n",
    "| 　 | 예측 클래스 0 | 예측 클래스 1 |\n",
    "|:-:|:-:|:-:|\n",
    "| 정답 클래스 1 | False Negative (FN) <br> (1) | True Positive (TP) <br> (3) |\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{accuracy} = \\frac{TP}{TP + FN}\n",
    "\\end{align*}\n",
    "\n",
    "- **거짓율(Fall-out/False Positive Rate):** 실제 클래스 0 값들 중 예측 클래스 1의 비율\n",
    "> - 정답 클래스 0중 예측으로 틀린 비율은?\n",
    "> - 다른 Metrics와 달리 낮을 수록 좋음\n",
    "> - 재현율(TPR)과 거짓율(FPR)은 양의 상관관계 존재\n",
    "\n",
    "| 　 | 예측 클래스 0 | 예측 클래스 1 |\n",
    "|:-:|:-:|:-:|\n",
    "| 정답 클래스 0 | True Negative (TN) <br> (3) | False Positive (FP) <br> (0) |\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{accuracy} = \\frac{FP}{FP + TN}\n",
    "\\end{align*}\n",
    "\n",
    "- **RUC Curve:**\n",
    "\n",
    "<center><img src='Image/Evaluation_ROC_Fit.png' width='500'></center>\n",
    "\n",
    "> **예시:**\n",
    "\n",
    "<center><img src='Image/Evaluation_ROC_Type.png' width='900'></center>"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "339.104px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
