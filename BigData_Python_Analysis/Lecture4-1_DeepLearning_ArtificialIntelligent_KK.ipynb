{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인공지능 시대\n",
    "\n",
    "- **인공지능에 대한 2종류의 사람**\n",
    "> **1) \"인공지능은 만능이다\"라는 환상을 가지고 있는 사람**   \n",
    "> **2) 열정적으로 공부하다 현재 수준과 한계에 혼란인 사람**\n",
    ">> **\"보통사람\"들을 위한 가이드로 가능한 쉽게 설명하는 것이 목적**\n",
    "\n",
    "**1) 정의:** 인간지능의 원리를 찾고(연구목표) 이를 프로그래밍으로 인공적 구현하는 것(연구대상)\n",
    "> - 1956년 처음 등장한 이래 아직도 미래기술로써 인식되는 '인공지능'\n",
    "> - 지능의 원리를 발견하고 나면 더이상 지능이 아니게 되는 과학 기반\n",
    "> - **AI Effect:** 발견된 것을 제외하고 아직 발견하지 못한 '지능의 비결'을 꾸준히 찾게 되는 것\n",
    "\n",
    "**2) 방향:** 규칙은 끊임없이 변하니 규칙(정답)찾는 것은 중지하고 기존 경험기반 기계가 스스로 통계적/확률적으로 판단하게 하자\n",
    "> - 기존의 경험은 '데이터를 통한 학습'으로 바뀌었으며 반드시 필요\n",
    ">> - **Supervised Learning:** 기계에게 문제와 답을 알려주며 학습시킨 후 답을 찾는 것으로 단순한 예측과 분류 등에 활용    \n",
    ">> - **Unsupervised Learning:** 기계에게 문제만 알려주며 패턴이라 룰 찾아 답을 스스로 예측하는 것으로 연관규칙이나 군집에 활용   \n",
    ">> - **Reinforcement Learning:** 아무것도 모른채 일단 실전에 뛰어들고 시행착오를 통해 학습   \n",
    ">>> - 답을 찾기위해 시행착오를 발생시킨 후 개선하는 방향\n",
    ">>> - 환경과 상호작용 속에서 답을 찾는 것으로 시간이 오래 소요되나 가장 강력하고 진보적인 방향     \n",
    "\n",
    "**3) 발전:**\n",
    "\n",
    "- **비교**\n",
    "> - 인공지능: 인간의 지능을 기계 등에 인공적으로 구현한 것\n",
    "> - 머신러닝: 인공지능의 한 분야로 컴퓨터가 학습할 수 있는 알고리즘과 기술을 개발하는 분야\n",
    "> - 딥러닝: 비선형 조합을 통해 높은 수준의 패턴학습을 시도하는 머신러닝 알고리즘\n",
    "\n",
    "<center>\"Evolution of Artificial Intelligence\"<img src='Image/DL_Evolution.png' width='600'></center>\n",
    "\n",
    "- **인공신경망과 딥러닝**\n",
    "> - 인공신경망은 머신러닝 방법론 중 하나로 1950년대 처음 제안\n",
    "> - 80~90년대에 널리 사용되다 계산 비용이 높아 90년대 후반에 약세\n",
    "> - 2000년대 이후 빅데이터 + 컴퓨팅파워 + 알고리즘고도화로 재부상\n",
    "> - 인공신경망의 한계는 결국 '최적화'가 어렵고 너무 많은 시간이 걸린다는 점\n",
    "> - 딥러닝이 인공신경망의 알고리즘을 개선하며 '비지도 학습'을 통해 최적화를 수행하는 방식으로 한계 극복 및 가능성 확장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 기술의 발전방향\n",
    "\n",
    "- **\"딥러닝의 발전사를 시간순으로 살펴본다!\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝의 시초 인공신경망의 등장(1940~1950)\n",
    "\n",
    "### 인공신경망(Artificial Neural Network: ANN)\n",
    "\n",
    "> - 인간의 신경구조를 네트워크로 표현할 수 있다고 최초로 제안 (McCulloch and Pitts, 1943)\n",
    "> - 딥러닝의 가장 핵심적인 기술로 인간 두뇌의 신경세포를 모방한 컴퓨터 알고리즘 네트워크 구조 \n",
    "> - 인간의 뇌는 많은 신경들이 존재하지만 정작 하나의 학습 알고리즘으로 여러가지를 동시에 학습\n",
    "> - 인간의 뇌는 뉴런들이 신호/자극(Input)을 받고 그 자극이 임계값(Weight)을 넘으면 신호를 전달(Output)하는 과정\n",
    "> - 마찬가지로 뇌를 모방하는 것은 수천개의 프로그램이 존재하는 것이 아니라 하나의 학습 알고리즘으로 접근\n",
    "> - ANN은 어떠한 형태의 함수(Function)도 근사할 수 있는 Universal Function Approximator로 알려져있음\n",
    "> - 우리가 알고싶어 하는 함수를 쉽게 근사하는 것이 목적\n",
    "> - 인공신경망은 네트워크를 형성한 인공뉴런이 학습을 통해 스스로 문제해결능력을 가지는 모델 전반 (위키백과)\n",
    "\n",
    "- **뉴런의 입출력**\n",
    "<center><img src='Image/DL_Neuron.png' width='500'></center>\n",
    "\n",
    "- **인공신경망의 입출력**\n",
    "> 1) 동그라미: 하나의 노드(뉴런)  \n",
    "> 2) 실선: 노드와 노드가 이어진 connection  \n",
    "\n",
    "<center><img src='Image/DL_ANN.png' width='500'></center>\n",
    "\n",
    "- **인공신경망의 문제점**\n",
    "> 1) 학습과정에서 파라미터의 최적값을 찾기 어려움\n",
    ">\n",
    "> - 여러 층에서 미분을 반복하면서 수치가 작아져 0이 되기도 하고 일부분의 에러를 최저 에러로 오판 하기도 함\n",
    ">\n",
    "> 2) 학습시간이 느리고 Overfitting 존재\n",
    ">\n",
    "> - 레이어를 많이 쌓으면 정확도는 올라가지만 연산이 기하급수적으로 늘어나고 Overfitting 가능성 존재\n",
    "\n",
    "\n",
    "### 단층퍼셉트론(Single-Layered Perceptron: SLP)\n",
    "\n",
    "**1) 구조:**\n",
    "> - 여러개의 노드(뉴런)들로 이루어진 하나의 인공신경망(단일층)으로 구성된 알고리즘 (Rosenblatt, 1958)\n",
    "> - 데이터가 각 노드의 입력으로 전달되고 각 노드는 입력데이터를 합산하여 하나의 값(분류 or 연속)으로 출력함\n",
    ">> **(1) 입력층(Input Layer):** 입력 데이터가 들어가는 곳  \n",
    ">> **(2) 가중치(Weight):** 입력 데이터 각각이 출력에 주는 영향도를 조절하는 매개변수로 클수록 해당 입력이 중요함  \n",
    ">> **(3) 은닉층(Hidden Layer):** 입력 데이터를 잘 섞어서 변환되는 곳  \n",
    ">> **(4-1) 활성함수(Activation Function):** 층을 쌓아 비선형 공간으로 변환(압축)하고 미분(Gradient)이 작동되게 하는 도구    \n",
    ">>> - 직선이 X의 변화 대비 Y의 변화라면, Gradient는 모든 가중치의 변화 대비 에러의 변화   \n",
    ">>> - 비선형 Scaling과 유사하며 데이터를 필터링하고 미분을 가능하게 함  \n",
    ">>> - 입력의 모든 데이터를 다음으로 보낼 필요 없이 특정 수준(범위)의 데이터만을 보내도록 제한을 걸어둔 것  \n",
    ">>> - 정해진 임계값 기준 은닉층의 출력을 최종적으로 원하는 출력값으로 변환  \n",
    ">>\n",
    ">> **(4-2) 임계값(Bias):** 노드(뉴런)이 얼마나 쉽게 1로 활성화(Activation)되는지를 조정하는 매개변수  \n",
    ">> **(5) 출력층(Output Layer):** 해결하고자 하는 문제의 성격에 맞춘 최종 출력값을 반환되는 곳 \n",
    ">> <center><img src='Image/DL_SLP_Custom.PNG' width='400'></center>\n",
    ">\n",
    "> - 현재의 딥러닝도 이러한 구조를 여러개의 노드와 레이어로 확장했을 뿐 근본적으로 같은 구조\n",
    "> - 퍼셉트론 접근으로 인간과 같은 인공지능을 만들 수 있을 것이라 기대\n",
    "\n",
    "**2) 선형 회귀/분류 알고리즘 예시:**\n",
    "> - **회귀문제의 신경망:**\n",
    "> <center><img src='Image/DL_Comparing1.PNG' width='200'></center>\n",
    "> - **분류문제의 신경망:**\n",
    "> <center><img src='Image/DL_Classification.PNG' width='350'></center>\n",
    "\n",
    "**3) 한계: NN의 첫번째위기**  \n",
    "> - 모든 데이터를 정확히 분류시킬때까지 학습이 진행되나 선형분리를 통해서만 데이터 분류가 가능함 (직선으로 나눌수 있는 분류만 가능)  \n",
    ">> - 선형 분류는 가능하지만 비선형 분류는 불가능함   \n",
    ">\n",
    "> - 단층이라 각 노드의 가중치를 변경할 수 없고 초기에 주어진 가중치가 변경되지 않고 유지됨 (가중치 조절 불가)  \n",
    ">> - 시작단계에서 가중치를 부여하여 분류결과를 변경이 가능하지만 학습의 개념이 아닌 단순한 분류문제 해결 (if-else와 동일)  \n",
    "\n",
    "<center><img src='Image/DL_SLP.png' width='500'></center>\n",
    "\n",
    "<center><img src='Image/DL_SLP_limit.gif' width='500'></center>\n",
    "<!-- (http://ecee.colorado.edu/~ecen4831/lectures/NNet3.html) -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인공신경망의 문제와 해결(1960~1980)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다층퍼셉트론(Multi-Layered Perceptron: MLP)\n",
    "\n",
    "**1) 방향:** 인공신경망을 여러 계층으로 구성한 다층/심층신경망으로 딥러닝의 출발  \n",
    "> - 단층퍼셉트론이 비선형을 분리할 수 없는 한계를 수학적으로 증명 (Minskey and Papert, 1969)\n",
    ">> - 위 예에서 2개의 직선 또는 1개의 곡선(여러개의 직선결합)을 이용하여 제대로 분류가 가능할 것? \n",
    ">> - 간단한 XOR 분류조차 할수 없는 수준임이 밝혀지며 인기가 사그라듬\n",
    ">\n",
    "> - 다층(여러개의 직선) 퍼셉트론으로 비선형 문제를 해결 (Hinton, 1986)  \n",
    ">\n",
    ">\n",
    "> - **비교:** ANN기법의 여러문제가 해결되면서 은닉층을 늘려서 학습의 결과를 향상시키는 방법이 등장하였고 이를 DNN(Deep Neural Network)라고 하며, 통상 은닉층을 2개이상 보유한 알고리즘을 지칭\n",
    "\n",
    "<center><img src='Image/DL_ANN_MLP.bmp' width='500'></center>\n",
    "<!-- (https://4ir.kisti.re.kr/) -->\n",
    "\n",
    "---\n",
    "\n",
    "<center><img src='Image/DL_Compare_MLP.jpg' width='500'></center>\n",
    "<!-- <center><img src='Image/DL_MLP_Custom.PNG' width='500'></center> -->\n",
    "\n",
    "**2) 분석방향:**\n",
    "> - **추정(학습):** 기계학습은 임의 가중치부터 시작하여 업데이트 하며 최종 가중치를 정하는 과정\n",
    "> - **출력:** 0 또는 1이면 선형분류(Linear Classifier)로 볼 수 있음\n",
    "> - **출력수:** 분류문제에 적용시 $n$개의 노드에 대해 $2^n$개 (1개의 노드시 2개 경우의 분류)\n",
    "> - **검증:** 추정된 출력과 실제 출력이 다를 때 에러를 줄이는 방향으로 가중치를 업데이트 \n",
    "\n",
    "**3) 한계:**\n",
    "> - 층(Layer)의 수가 많아지면서 늘어나는 Weights를 수동으로 학습하기에 한계가 있기에 여전히 학습이란 개념은 적용 불가\n",
    "\n",
    "\n",
    "### 역전파(Back Propagation: BP)\n",
    "\n",
    "> **\"역방향으로 데이터(오차)를 전달한다\"**  \n",
    "> - MLP를 효과적으로 학습시킬 수 있는 역전파 알고리즘 제안 (Rumelhart, Hinton, and Williams, 1986)\n",
    "> - 학습을 통해 가중치를 업데이트 할 수 있게 됨\n",
    "\n",
    "<center><img src='Image/DL_Backpropagation.png' width='500'></center>\n",
    "\n",
    "- **학습방향:** 처음 설정된 각 노드별 가중치가 우리가 원하는 결과(검증Metric)를 만들 수 있도록 지속 업데이트\n",
    "\n",
    "<center><img src='Image/DL_MLP_Learning.PNG' width='600'></center>\n",
    "\n",
    "> **(1) 네트워크 초기화:** 가중치의 초기값이 필요하며 일반적으로 무작위로 초기화 됨   \n",
    "> - **초기값이 모두 같으면 모든 노드들이 같은 값을 받고 같은 값을 출력하고 오차 역전파도 동일하게 전파되므로 다른값 필요**   \n",
    ">\n",
    "> **(2) 전파:** 초기화된 가중치들이 퍼셉트론을 거쳐 출력\n",
    ">> $\\hat{Y}_{init} = f(\\sum_{i}^{k} w_i x_i - \\theta)$  \n",
    ">\n",
    "> **(3) 오차 평가:** Cost Function\n",
    ">> **회귀문제:** $MSE = \\frac{1}{k} \\sum_{i=1}^{k} (\\hat{Y}_{init} - Y)^2$    \n",
    ">> **분류문제:** $Cross Entropy = \\sum_{i=1}^{k} \\left[ - \\color{red}{\\hat{Y}_{init} log (Pr(\\hat{Y}_{init}))} - \\color{blue}{(1-\\hat{Y}_{init}) log (1-Pr(\\hat{Y}_{init}))} \\right]$    \n",
    ">\n",
    "> **(4) 역전파:** 각 가중치 별 현재 에러에 미치는 영향 계산 \n",
    ">> $\\frac{\\delta E}{\\delta w} = \\frac{\\delta}{\\delta w} \\frac{1}{k} \\sum_{i=1}^{k} (\\hat{Y}_{init} - Y)^2$  \n",
    ">\n",
    "> **(5) 조정:** 에러를 줄이기 위해 가중치를 업데이트(Gradient Descent) \n",
    ">> $w_i^{new} = w_i^{old} - \\alpha \\Delta w_i^{old} = w_i^{old} - \\alpha \\frac{\\delta E}{\\delta w_i}$  \n",
    "> - **$\\alpha$: 학습률(Learing Rate)이 높으면 최적점을 벗어나 오차가 증가될 수 있음**  \n",
    ">\n",
    "> **(6) 종료:** 허용오차 범위 내로 들어오면 최종 가중치로 반영\n",
    ">> $w_i^{final} = w_i^{new}$  \n",
    "\n",
    "<center><img src='Image/DL_GD.PNG' width='400'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝의 등장과 암흑기(1980~2000)\n",
    "\n",
    "- **딥러닝(Deep Learning: DL)**\n",
    "\n",
    "> **\"인공신경망의 다층구조가 심화(Deep)된 네트워크 구조의 알고리즘\"**\n",
    ">\n",
    "> <center><img src='Image/DL_What-is-Deep-Learning.png' width='500'></center>\n",
    "<!-- (https://www.michaelchimenti.com/2017/11/deep-neural-nets-software-2-0/) -->\n",
    "\n",
    "| 장점 | 단점 |\n",
    "|:-:|:-:|\n",
    "|- 연속형 및 범주형 변수 모두 분석 가능<br>     - 입력 변수들 간의 비선형 특성 추정 가능<br>     - 기계학습 알고리즘에 비해 예측력 우수<br>     - Feature Engineering 반영(방향)<br>     - 데이터의 양이 많아지면 성능은 계속 상승 | - 복잡한 신경망은 작동 시간이 오래 걸림(고사양   PC필요)<br>     - 데이터 입력이 일정하지 않아 결과도 일정하지 않음(Not Robust)<br>     - 가중치를 정확히 추정(해석)할 수 없어서 결과해석 불가 |\n",
    "\n",
    "- **한계: NN의 두번째위기** \n",
    "> **1) Vanishing Gradients:** \n",
    "> - Activation Function의 양끝의 기울기가 0에 가까워 학습이 진행되면 기울기가 0에 가까워져 학습이 안되고 성능이 떨어짐\n",
    ">\n",
    "> <center><img src='Image/DL_MLP_Learning.PNG' width='600'></center>\n",
    ">\n",
    "> <center><img src='Image/Vanishing_Gradient_Sigmoid.png' width='500'></center>\n",
    ">\n",
    "> - (Forward) BP는 멀리 전파될 때 계산량이 많아지지만 전파되는 값의 크기가 점차 작아지는 문제 존재  \n",
    "> - (Backward) 오차 역시 역전파로 전달되는 값이 작아지고 복잡한 구조로 Cost Function이 Convex가 아니다 보니 최적값이 아닌 곳에서 학습을 중지\n",
    "> \n",
    "> <center><img src='Image/Vanishing_Gradient.PNG' width='500'></center>\n",
    ">\n",
    "> **2) Curse of Dimensionality:** 빅데이터일수록 성능이 떨어짐\n",
    "> - 고차원의 저주와 과접합 문제라고도 함\n",
    "> - 딥러닝은 추정해야할 가중치들이 많아서 많은 데이터가 필요\n",
    ">> - 인간의 뇌는 스스로가 Unlabeled Data를 사용해서 학습하고 의사결정하는 Unsupervised Learning\n",
    ">> - 딥러닝의 현실은 아직 Unsupervised Learning의 성능이 높지 않고 Supervised Learning에 집중\n",
    ">> - 우리가 보유한 데이터는 Unlabeled가 훨씬 많고 Labeled 데이터는 많지 않음\n",
    ">> - 적은 Labeled 데이터로 딥러닝을 학습하면 Hidden Layer가 1개인 경우보다 성능이 떨어지는 경우 발생 \n",
    "> - 적은 학습데이터에 특화되어 학습되어 Overfitting이 생기는 것이고 고차원(빅데이터)일 수록 점점 심해짐\n",
    ">\n",
    "> **3) Low Learning Time:** 비용이 너무 많이듬\n",
    "> - 연산량은 급증하는데 당시의 하드웨어에서는 큰 부담과 한계\n",
    ">\n",
    "> <center><img src='Image/History_LimitHardware.png' width='500'></center>\n",
    ">\n",
    "> **4) Local Minimum:** 수학적 추정이 아닌 알고리즘 최적화 이기에 진짜 최소값(Global Minimum)이 아니라 국소 최소값(Local Minimum)에서 비용함수가 최소가 될 수 있고 초기값 문제도 연관\n",
    ">\n",
    "> <center><img src='Image/DL_LocalMinimum.png' width='500'></center>\n",
    "\n",
    "\n",
    "## 머신러닝의 호황기(2000~2006)\n",
    "\n",
    "> **\"2000년대 들어, 인공신경망 알고리즘(한계 미해결) 대신 비선형 함수를 사용한 다양한 머신러닝 알고리즘들이 대세\"**\n",
    "\n",
    "**1) Support Vector Machine:**\n",
    "> - 클래스를 구분하는 경계면을 찾아 데이터의 클래스를 예측\n",
    "> - 인공신경망과 별개로 개발된 지도학습 기반의 분류 예측기법\n",
    "> - 오차의 최소화 이외에 클래스 사이의 여백(Margin)을 최대화 하는 경계를 찾는 것이 목표\n",
    "> - 구분 경계면이 직선이 아닌 경우 커널을 사용하여 높은 차원의 데이터로 변형 학습\n",
    ">\n",
    "> <center><img src='Image/ML_SVM.png' width='500'></center>\n",
    "\n",
    "**2) K Nearest Neighbors:**\n",
    "> - 분류 알고리즘의 일종으로 분석가(사용자)가 정의하는 샘플수($K$)에 따라 데이터들의 실제값과의 거리를 기준으로 입력값의 클래스를 예측하는 지도학습 기반의 예측기법\n",
    ">\n",
    "> <center><img src='Image/ML_KNN.png' width='600'></center>\n",
    ">\n",
    ">> - 샘플수($K$)는 통상 데이터의 갯수의 $\\sqrt n$ 보다 작은 값으로 통상 홀수를 사용하는 편\n",
    ">> - 샘플수가 너무 작으면 노이즈 때문에 High Variance 문제가 생기고, 샘플수가 너무 크면 다른 클래스의 값들이 포함될 가능성이 높아 High Bias 문제가 생김\n",
    "> - 데이터의 거리는 Euclidean, Manhattan, Minkowski, Correlation 등의 방법이 사용됨\n",
    ">> - 입력이 연속형이면 대게 유클리디안 거리 사용\n",
    ">> - 입력이 이산형이면 대게 해밍거리를 사용\n",
    "> - 입력값에서 가장 가까운 K개의 실제값을 거리 탐색 후, 분류 문제면 다수 투표를 수행하고, 회귀 문제이면 평균 계산으로 입력값의 클래스 예측\n",
    "> - 변수들은 Normalization으로 Scaling 하는 편\n",
    "\n",
    "**3) 머신러닝의 한계:**\n",
    "> - 대부분 지도학습 기반의 알고리즘\n",
    "> - 실제 세상에 존재하는 문제의 대부분은 Unlabeled 데이터기 때문에 성능이 좋음에도 한계에 봉착\n",
    "\n",
    "\n",
    "## 비지도학습과 딥러닝의 재조명(2006~2010)\n",
    "\n",
    "> **\"새로운 학습 방법이 재조명되면서 인공신경망이 다시 학계의 주목\"**    \n",
    "> **\"Unsupervised Learning, 즉 Label이 없는 데이터로 미리 충분히 학습한 후, 역전파 알고리즘으로 Supervised Learing 수행\"**\n",
    "> - 선학습법(Pre Training)을 적용한 RBM 알고리즘을 발표 (Hinton et al. 2006)\n",
    "> - Restricted Boltzmann Machine: Unlabeled Data로 선학습 한 후 역전파를 통해 Supervised Learning 수행\n",
    "> - 군집화(Clustering)라는 Unsupervised Learning으로 데이터의 노이즈를 감소시키고 하위층들을 하나하나 최적화시키며 학습\n",
    "> - 최적의 Training Initial Value를 지정할 수 있는 계기\n",
    "> - 비지도학습을 이용하면서 MLP 약점의 많은 부분이 극복\n",
    "> - 실제 아기들은 단어/음/뜻/문장 등을 전혀 모르는 상태에서 스스로 각 문법들을 Unsupervised Learning하며 학습하고 그 후에 정답으로 Supervised Learning을 수행\n",
    ">\n",
    "> <center><img src='Image/Restricted_Boltzmann_Machine.png' width='600'></center>\n",
    ">\n",
    "> - **장점:** MLP의 단점들이 많이 해결\n",
    ">> - Unlabeled 데이터 사용가능하고 선학습으로 Vanishing Gradient, Overfitting, Local Minimum 문제가 해결 가능할 것이라 여겨짐 (Bengio, 2009)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 알고리즘의 발전(2010~)\n",
    "\n",
    "> **\"RBM 이외에, Supervised Learning 문제에서 해법을 찾으려는 노력들이 존재\"**\n",
    "\n",
    "**1) Vanishing Gradients의 해결:** ReLU\n",
    "> - 활성함수를 Logistic/Sigmoid 대신 ReLU(Rectified Linear Unit)를 사용하여 Vanishing Gradient의 문제를 해결 (Hinton et al. 2010)\n",
    "> - 기존 활성함수는 양끝이 기울기가 0에 가까워 계산이 반복되거나 중첩되면 0이 될 가능성 높음\n",
    "> - ReLU 활성함수는 기울기가 0으로 감소하는 현상이 없고 학습성능도 높아짐\n",
    "> - 미분 중첩에서의 문제를 해결하면서 선학습(Pre Training)도 필요 없어짐 (Bordes and Bengio. 2011)\n",
    ">\n",
    "> <center><img src='Image/Logistic_ReLU.png' width='400'></center>\n",
    ">\n",
    "<!-- <center><img src='Image/DL_ActivationFunction.png' width='500'></center> -->\n",
    "<!-- (https://t1.daumcdn.net/cfile/tistory/22293C50579F7BBF13) -->\n",
    ">\n",
    "> - **다양한 종류의 활성함수:**\n",
    "> <center><img src='Image/DL_ActivationFunction_Type.png' width='700'></center>\n",
    ">\n",
    "<!-- <center><img src='Image/DL_ActivationFunction_Type_All.png' width='700'>(https://miro.medium.com/max/814/1*F9-nc6ez5GOJ1mdB3TLlow.png)</center> -->\n",
    "\n",
    "**2) Local Minimum의 해결:** Global Minimum $\\approx$ Local Minimum\n",
    "> - 고차원이나 Non-convex 최적화 문제에서 Local Minimum들은 서로 유사할 것이며 Global Minimum과 큰 차이가 없을 것 (Bengio et al. 2014)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과적합 개선 아이디어(Overfitting Problem)\n",
    "\n",
    "**1) Drop Out:** Hidden Layer의 일부 뉴런을 무작위 확률적으로 제외하면서 학습 \n",
    "> **\"기업의 모든 직원이 함께 일하는 것보다 소그룹의 결과를 통합하는 것이 더욱 효율적일 수 있음\"**    \n",
    "> **\"각 단계의 모델은 약한 학습모델이지만 약한모델들이 합쳐져 강력한 예측력 구현\"**   \n",
    "> - Labeled 데이터의 부족과 Overfitting 문제 해결을 위해 Drop Out 정규화 제안 (Hinton et al. 2012)\n",
    "> - 학습할 때마다 일부 유닛만을 사용하고 이를 반복해서 합치는 방식으로 Ensemble과 유사\n",
    "> - 빠진 뉴런을 포함하여 예측 하기에 여러개의 독립적인 내부표현 학습가능\n",
    "> - 네트워크가 뉴런의 특정 가중치에 덜 민감해짐\n",
    "> - 더욱 일반화에 기여가 가능하고 훈련 데이터를 지나칠 가능성이 적어짐\n",
    "> - 너무 낮은 비율은 영향이 없고 너무 높은 비율은 과소 적합을 하기에 20~50\\% 권장\n",
    "> - Learning Rate(LR)과 Momentum을 높여 사용(LR:10 -> 100, Momentum: 0.9 or 0.99)\n",
    "> - LR이 높을 시 네트워크 가중치의 크기를 줄이면 높은 성능 가능 (Ridge와 유사)\n",
    "\n",
    "<center><img src='Image/DL_DropOut.png' width='500'></center>\n",
    "<!-- (https://t1.daumcdn.net/cfile/tistory/99324B335D383CBD1B) -->\n",
    "\n",
    "> - 랜덤한 유닛을 사용하는 것 대신, 연결선을 랜덤하게 사용하는 DropConnect 방법도 존재 (Wan et al. 2013)\n",
    "\n",
    "<center><img src='Image/DL_Dropout_Dropconnect.png' width='700'></center>\n",
    "\n",
    "---\n",
    "\n",
    "**2) Early Stopping:** 테스트 데이터의 성능을 쉽게 끌어낼 수 있는 경우 일찍 종료하는 방법   \n",
    "> **\"데이터가 Train/Evaluate/Test으로 구분되어 있을때, Evaluate 데이터가 낮은 오차가 나오면 멈추므로 과적합 낮춤\"**   \n",
    "\n",
    "<center><img src='Image/DL_Overfitting_Epoch.png' width='600'></center>\n",
    "\n",
    "<center><img src='Image/DL_Overfitting_EarlyStopping.png' width='600'></center>\n",
    "<!-- (https://kevinthegrey.tistory.com/110) -->\n",
    "\n",
    "---\n",
    "\n",
    "**3) Regularization:** Cost Function 개선   \n",
    "> **\"추정 계수가 커지면 활성함수를 통해 기울기가 급변하게되어 오류 최소화가 어렵고 과적합 여지가 높아짐\"**   \n",
    ">\n",
    "> **(1) L1 Panelty:** LASSO Regression에 사용한 Cost Function 반영    \n",
    "> - 중요도가 적은 가중치는 0이 되기에 과적합이 방지\n",
    "> - 변수선택 효과가 있어 모델 복잡도를 효과적으로 제약\n",
    "> - 변수의 수가 데이터의 수보다 많은 경우도 사용가능하기에 고차원의 데이터도 적용가능(불필요 변수를 0으로 바꿈)\n",
    "> - 페널티의 크기는 Hyperparameter로 사전 결정되며 교차검증이나 유사 방법으로 결정\n",
    "> - 페널티 효과는 가중치 크기에 비례하고 가중치 크기는 데이터 양에 비례\n",
    "> - 모델에 제약을 주며 정확도를 상승시킴   \n",
    ">\n",
    "> **(2) L2 Panelty:** Ridge Regression에 사용한 Cost Function 반영   \n",
    "> - 모든 가중치를 일률적으로 작게 만드는 경향  \n",
    "> - 중요도가 적은 가중치는 0이 아닌 작은 값을 가지게 하므로 변수선택 효과 없음\n",
    "> - 최적 모델 선택에 더 적합하므로 주료 사용됨\n",
    "\n",
    "<center><img src='Image/DL_CF_L1L2.png' width='600'></center>\n",
    "\n",
    "<center><img src='Image/DL_CF_L1L2_Compare.png' width='600'></center>\n",
    "<!-- (https://kevinthegrey.tistory.com/110) -->\n",
    "\n",
    "---\n",
    "\n",
    "**4) Others:**\n",
    "\n",
    "> **(1) Batch:** 모델 내부 파라미터를 업데이트 하기 전 샘플의 개수\n",
    "> - **Batch Gradient Descent:** Batch Size = Size of Training Set\n",
    "> - **Stochastic Gradient Descent:** Batch Size = 1\n",
    "> - **Mini-Batch Gradient Descent:** 1 < Batch Size < Size of Training Set\n",
    ">\n",
    "> **(2) Epoch:** 훈련데이터의 알고리즘 수행 횟수 $[1,\\text{Size(Training)}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다양한 알고리즘의 등장(Several Algorithms)\n",
    "\n",
    "> **\"딥러닝의 전성기 대두\"**\n",
    "> - 인공신경망의 고전적 문제들은 대부분 해결\n",
    "> - 빅데이터의 폭발적인 증가\n",
    "> - 하드웨어 기술의 발전\n",
    "> - 초창기 CNN과 RNN의 큰 발전\n",
    "\n",
    "**1) CNN(Convolutional Neural Network)의 발전**\n",
    "> - 영상처리를 위해 특수 고안된 구조로 데이터의 패턴을 추출하고(Convolution) 차원을 줄여 일반적인 패턴으로 정교화(Pooling)\n",
    "> - 추정하는 가중치(Weight)를 공유하기 때문에 학습속도가 빠르고 일반화 능력이 우수\n",
    ">\n",
    "> **(1) Lenet5**\n",
    "> - 6층으로 구성된 CNN으로 3개의 Convolution Layer + 2개의 Polling Layer + 1개의 Fully Connected Layer\n",
    "> - Convolutional Layer의 패턴 추출 시간이 많이 걸려 MLP보다 3배 정도 느림\n",
    ">\n",
    "> **(2) Alexnet**\n",
    "> - Hinton 교수진이 2012년에 개발한 딥러닝의 혁명을 일으킨 CNN 모델\n",
    "> - 5개의 Convolution Layer + 3개의 Fully Connected Layer + 1000개의 Softmax Neuron\n",
    "> - 활성함수는 ReLU + GPU를 사용한 Convolution 연산\n",
    "> - Lenet5에 비해 학습시간 단축 및 FC에 Dropout을 사용하여 과적합 방지\n",
    ">\n",
    "> **(3) DeepFace**\n",
    "> - 대규모 딥네트워크를 사용하여 얼굴 영상의 표상을 학습\n",
    "> - 9층의 DNN 형식으로 CNN과 달리 노드들이 가중치를 공유하지 않음\n",
    "> - 특징벡터들에 정렬 알고리즘을 반영하여 높은 얼굴인식 성능\n",
    ">\n",
    "> **(4) GoogLenet**\n",
    "> - 22층의 CNN으로 입센셥 모듈이라는 블록을 반복 사용하는 모델\n",
    "> - 사물의 분류와 검출 프로젝트에서 신기록 갱신\n",
    "> - 제한된 자원을 최대한 이용하는 구조\n",
    "> - 인셉션 모듈은 CNN의 최적 희소구조를 찾아내고 이를 사용가능한 패턴으로 근사\n",
    "\n",
    "**2) RNN(Recurrent Neural Network)의 발전**\n",
    "> - 뉴런들이 순환구조로 연결되어 과거 정보를 기억하는 동적 시스템\n",
    "> - 다양한 순차데이터(Sequence)를 처리\n",
    "> - Vanishing Gradient 문제가 존재\n",
    ">\n",
    "> **(1) LSTM**\n",
    "> - Vanishing Gradient 문제를 해결하고자 RNN에 4개의 상호작용 층을 추가\n",
    "> - Vanishing Gradient 문제를 효과적으로 잡아내고 안정적인 학습이 가능\n",
    ">\n",
    "> **(2) GRU**\n",
    "> - LSTM보다 간략화한 구조로 한국인 조경현 박사님이 개발 (Cho et al. 2014)\n",
    "\n",
    "**3) GAN(Generative Adversarial Network)의 등장**\n",
    "> - 구글브레인 Ian Goodfellow가 2014년 NIPS 학회에서 발표\n",
    "> - 비지도학습 기반의 신경망 알고리즘으로 진짜같은 가짜를 만드는 기술\n",
    "> - 2개의 신경망 모델의 경쟁을 통해 학습하면서 결과 생성\n",
    ">> - **생성자:** 실제 데이터를 학습해 거짓데이터 발생\n",
    ">> - **감별자:** 생성자가 만든 데이터를 실제인지 거짓인지 판별\n",
    "> - 생성자와 감별자의 반복으로 실제에 가까운 거짓 데이터 생성\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 가중치 추정 최적화(Optimization)\n",
    "\n",
    "> **\"손실함수의 값을 가능한 낮추는 매개변수를 찾는 것\"**  \n",
    "> **\"Prerequisite: Derivatives, Partial Derivatives, Chain Rule\"**\n",
    ">\n",
    "> **(1) 네트워크 초기화:** 가중치의 초깃값이 필요하며 일반적으로 무작위로 초기화 됨   \n",
    ">\n",
    "> **(2) 전파:** 초기화된 가중치들이 퍼셉트론을 거쳐 출력\n",
    ">\n",
    "> **(3) 오차 평가:** Cost Function\n",
    ">\n",
    "> **(4) 역전파:** 각 가중치 별 현재 에러에 미치는 영향 계산 \n",
    ">> $\\frac{\\delta E}{\\delta w} = \\frac{\\delta}{\\delta w} \\frac{1}{k} \\sum_{i=1}^{k} (\\hat{Y}_{init} - Y)^2$  \n",
    ">\n",
    "> **(5) 조정:** 에러를 줄이기 위해 가중치를 업데이트<span style=\"color:red\">**(Gradient Descent)**</span>   \n",
    ">> $w_i^{new} = w_i^{old} - \\alpha \\Delta w_i^{old} = w_i^{old} - \\alpha \\frac{\\delta E}{\\delta w_i}$  \n",
    ">\n",
    "> **(6) 종료:** 허용오차 범위 내로 들어오면 최종 가중치로 반영 \n",
    ">> $w_i^{final} = w_i^{new}$ \n",
    "\n",
    "- **예시:**\n",
    "> <center>$총비용(Y) = w_{정장}X_{정장} + w_{셔츠}X_{셔츠} + w_{타이}X_{타이}$</center>\n",
    "> <center><img src='Image/DL_Optimization_Example.png' width='400'></center>\n",
    ">\n",
    "> (1-0) **초기가중치 세팅:** 정답가중치($w^{final}$)가 각각 150원, 50원, 10원으로 총비용은 580원    \n",
    ">\n",
    "> (1-1) **$\\hat{Y}$ 추정:** 초기가중치($w^{initial}$)가 모두 150원이라면 총비용은 1500원 \n",
    ">\n",
    "> (1-2) **비용함수 추정:** $MSE = \\frac{1}{2}(580 - 1500)^2 = 423200$    \n",
    ">\n",
    "> (1-3) **가중치 별 비용함수 영향도 계산:** $\\frac{\\delta MSE}{\\delta w_i}$\n",
    ">> $\\frac{\\partial MSE}{\\partial w_i} = \\frac{\\partial Y}{\\partial w_i} \\frac{d MSE}{dY} = X_i (\\hat{Y} - Y)$\n",
    ">\n",
    "> (2-0) **가중치 업데이트:** $w_i^{after} = w_i^{initial} - \\alpha \\frac{\\delta MSE}{\\delta w_i} = w_i^{initial} - \\alpha X_i(\\hat{Y} - Y)$ \n",
    ">> - **정장:** $w_{정장}^{after} = w_{정장}^{initial} - \\alpha X_{정장} (\\hat{Y} - Y) \\\\ = 150 - (1/500)2(920) = 146.32$\n",
    ">>\n",
    ">> - **셔츠:** $w_{셔츠}^{after} = w_{셔츠}^{initial} - \\alpha X_{셔츠} (\\hat{Y} - Y) \\\\ = 150 - (1/500)5(920) = 140.8$\n",
    ">>\n",
    ">> - **타이:** $w_{타이}^{after} = w_{타이}^{initial} - \\alpha X_{타이} (\\hat{Y} - Y) \\\\ = 150 - (1/500)3(920) = 144.48$\n",
    ">\n",
    "> (2-1) **$\\hat{Y}$ 업데이트:** 총비용은 1430.08원\n",
    ">\n",
    "> (2-2) **비용함수 업데이트:** $MSE = \\frac{1}{2}(580 - 1430.08)^2 = 361318$ \n",
    ">\n",
    "> (2-3) **가중치 별 비용함수 영향도 계산:** $\\frac{\\delta MSE}{\\delta w_i}$\n",
    ">\n",
    "> (...) **비용함수가 더이상 변하지 않는 최소값이 될때까지 반복하여 참값에 가까운 추정치 확보**\n",
    "\n",
    "- **결론:**\n",
    "> <center><img src='Image/DL_Forward_Backward.png' width='600'></center>\n",
    ">\n",
    "> - **목표: 정답(총비용)을 맞추기 위해 오차($MSE$)를 최소로 하는 가중치($w$)를 추정**\n",
    ">\n",
    ">\n",
    "> - **이슈:** 딥러닝으로 갈수록 추정해야할 가중치($w$)가 너무 많아 선형회귀분석이나 로지시틱회귀분석에서 계수(가중치)를 추정하던 방식을 사용할 수 없음\n",
    ">\n",
    ">> - **결정론적 접근:** 최소제곱추정량(Least Square Estimator)\n",
    ">> - **확률론적 접근:** 최대가능도추정량(Maximum Likelihood Estimator)\n",
    ">\n",
    "> - **대응:**\n",
    ">\n",
    ">> - **최적화 알고리즘:** 오차가 최소가 되는 위치를 찾아주는 수학 이론\n",
    ">> - **Gradient Descent Algorithm:** 미분계수에 비례하여 가중치를 업데이트\n",
    ">> - 미분이 최소 또는 0일때의 가중치가 정답\n",
    ">>\n",
    ">>> - **이동크기:** 미분계수가 크면 가중치를 크게 변경하고 작으면 가중치를 작게 변경\n",
    ">>> - **이동속도:** 학습율(Learning Rate)을 사용하여 가중치 변경 폭을 추가로 정할 수 있음\n",
    ">>\n",
    ">> <center><img src='Image/DL_Optimization_Flow.png' width='600'></center>\n",
    "\n",
    "- **최적화 알고리즘 종류 및 방향:**\n",
    "\n",
    "<center><img src='Image/DL_Optimization_Direction.png' width='700'></center>\n",
    "\n",
    "<!-- <center><img src='Image/DL_Optimization_Direction_KR.png' width='700'>(https://www.slideshare.net/yongho/ss-79607172)</center> -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝 알고리즘의 진단(Evaluation) 및 완성(End)\n",
    "\n",
    "**\"성능(Test)을 향상시키기 위해 동작 여부를 테스트하여 최적의 가이드를 함께 제시\"**\n",
    "\n",
    "> **1) 학습성능변화:** 하이퍼파라미터의 변화에 따른 성능변화로 최적 하이퍼파라미터 선택    \n",
    ">\n",
    ">> - 데이터 분리 비율\n",
    ">> - 가중치 초기값\n",
    ">> - 은닉층의 수\n",
    ">> - Regularized 비중\n",
    ">> - DropOut 비율\n",
    ">> - Cost Function 선정\n",
    ">> - Learning Rate 크기\n",
    ">> - Early Stopping 고려기간\n",
    ">> - Batch 크기\n",
    ">> - Epoch 횟수\n",
    ">\n",
    "> **2) 에러분석:** 에러를 수동으로 분석하여 가치있는 Feature를 찾아내어 반영    \n",
    "\n",
    "---\n",
    "\n",
    "<center><img src='Image/DL_hyperparameter_table_simple.png' width='350'></center>\n",
    "\n",
    "<center><img src='Image/DL_hyperparameter_table.PNG' width='450'></center>\n",
    "\n",
    "---\n",
    "\n",
    "<center><img src='Image/DL_hyperparameter_epoch.png' width='600'></center>\n",
    "\n",
    "<center><img src='Image/DL_hyperparameter_search_simple.jpg' width='800'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "> **1) \"1950년대 퍼셉트론(Perceptron)에서 시작된 인공신경망 연구는 1980년대 오류의 역전파알고리즘(Error Backpropagation Algorithm)으로 다층퍼셉트론(Multilayer perceptron)을 학습할 수 있게 되면서 발전을 이루었다.\"**\n",
    ">\n",
    "> **2) \"하지만 Gradient Vanishing, Labeled 데이터의 부족, Overfitting, Local Minimum 등이 잘 해결되지 못해 2000년대 초까지 인공신경망 연구는 잠시 지지부진 하였고, 2006년부터 볼츠만머신을 이용한 Unsupervised Learning인 Restricted Boltzmann Machine(RBM), Deep Belief Network(DBN), Deep Boltzmann Machine(DBM), Convolutional Deep Belief Network 등이 개발되면서 Unlabeled data를 이용하여 Pre-training을 수행할 수 있게 되어 위에 언급된 다층퍼셉트론의 한계점이 극복되었다.\"**\n",
    ">\n",
    "> **3) \"2010년부터 빅데이터를 적극적으로 이용함으로서 수많은 Labeled 데이터를 사용할 수 있게 되었고, Rectified Linear Unit (ReLU), DropOut, DropConnect 등의 발견으로 Vanishing Gradient문제와 Overfitting 이슈를 해결하여 Supervised Learning이 가능하게 되었으며, Local Minimum 문제도 High Dimension Non-convex Optimization에서 얼마나 Global Minimum과 차이가 나는지 연구되고 있으며 큰 차이가 없다라는 연구도 있다.\"**"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "428px",
    "left": "146px",
    "top": "243.12px",
    "width": "388.52px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
